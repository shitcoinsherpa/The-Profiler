"""
FBI-Style Behavioral Profiling System
Gradio application for multimodal AI-powered psychological assessment.
"""

import warnings
import asyncio
import os

# Suppress noisy Windows asyncio connection reset warnings
warnings.filterwarnings("ignore", message=".*ConnectionResetError.*")
if hasattr(asyncio, 'WindowsProactorEventLoopPolicy'):
    asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())

# Initialize centralized logging before other imports
from logger import setup_logging
setup_logging(
    level=os.getenv("LOG_LEVEL", "INFO"),
    log_file=True,
    console=True
)

import gradio as gr
import json
import tempfile
from datetime import datetime
from profiler import BehavioralProfiler, ModelSelection, run_dev_meta_analysis
from config_manager import ConfigManager
from models_config import (
    ESSENCE_MODEL_CHOICES,
    MULTIMODAL_MODEL_CHOICES,
    AUDIO_MODEL_CHOICES,
    LIWC_MODEL_CHOICES,
    SYNTHESIS_MODEL_CHOICES,
    get_default_model_for_stage,
    DEV_META_MODELS,
    DEFAULT_DEV_META_MODEL
)
from video_downloader import download_video, is_valid_url, get_video_info
from database import get_database, ProfileDatabase
from pdf_generator import generate_pdf_report, REPORTLAB_AVAILABLE
from cache_manager import get_cache, VideoCache
from prompt_templates import (
    get_template_manager,
    PROMPT_STAGES,
    DEFAULT_PROMPTS
)


# Create FBI-themed Gradio theme based on Glass
def create_fbi_theme():
    """Create custom FBI-themed Gradio theme based on Glass."""
    return gr.themes.Glass(
        primary_hue=gr.themes.Color(
            c50="#e8f4ff",
            c100="#d1e9ff",
            c200="#a3d3ff",
            c300="#75bdff",
            c400="#4a9eff",  # Main FBI blue
            c500="#2d8aef",
            c600="#1a6fc7",
            c700="#155a9f",
            c800="#104878",
            c900="#0a3050",
            c950="#051828",
        ),
        secondary_hue="slate",
        neutral_hue="slate",
        font=gr.themes.GoogleFont("Inter"),
        font_mono=gr.themes.GoogleFont("IBM Plex Mono"),
    ).set(
        # Dark mode optimizations
        body_background_fill="#0a0e1a",
        body_background_fill_dark="#0a0e1a",
        background_fill_primary="#0f1320",
        background_fill_primary_dark="#0f1320",
        background_fill_secondary="#1e2842",
        background_fill_secondary_dark="#1e2842",

        # Border styling
        border_color_primary="#2d3a5f",
        border_color_primary_dark="#2d3a5f",
        block_border_width="1px",

        # Button styling
        button_primary_background_fill="linear-gradient(135deg, #4a9eff 0%, #2d6bbf 100%)",
        button_primary_background_fill_dark="linear-gradient(135deg, #4a9eff 0%, #2d6bbf 100%)",
        button_primary_background_fill_hover="linear-gradient(135deg, #5eaaff 0%, #3d7bcf 100%)",
        button_primary_background_fill_hover_dark="linear-gradient(135deg, #5eaaff 0%, #3d7bcf 100%)",
        button_primary_text_color="#ffffff",
        button_primary_text_color_dark="#ffffff",

        # Input styling
        input_background_fill="#0a0e1a",
        input_background_fill_dark="#0a0e1a",
        input_border_color="#2d3a5f",
        input_border_color_dark="#2d3a5f",

        # Text colors
        body_text_color="#e8eaf0",
        body_text_color_dark="#e8eaf0",
        body_text_color_subdued="#6b7280",
        body_text_color_subdued_dark="#6b7280",

        # Panel/block styling
        block_background_fill="#1e2842",
        block_background_fill_dark="#1e2842",
        panel_background_fill="#0f1320",
        panel_background_fill_dark="#0f1320",

        # Shadows and effects
        shadow_spread="4px",
        block_shadow="0 2px 8px rgba(0,0,0,0.3)",
        block_shadow_dark="0 2px 8px rgba(0,0,0,0.5)",
    )


# Minimal custom CSS - only for elements that need special handling
MINIMAL_CSS = """
/* Header styling */
.app-header {
    text-align: center;
    padding: 20px 0;
    margin-bottom: 10px;
    border-bottom: 1px solid #2d3a5f;
}

.app-title {
    font-size: 28px;
    font-weight: 700;
    color: #4a9eff;
    margin: 0 0 8px 0;
    letter-spacing: 1px;
}

.app-subtitle {
    font-size: 14px;
    color: #6b7280;
    margin: 0;
}

.app-attribution {
    font-size: 12px;
    color: #4a9eff;
    margin-top: 8px;
}

.app-attribution a {
    color: #4a9eff;
    text-decoration: none;
}

.app-attribution a:hover {
    text-decoration: underline;
}

/* Section headers */
.section-header {
    color: #4a9eff;
    font-size: 14px;
    font-weight: 600;
    letter-spacing: 1px;
    text-transform: uppercase;
    margin: 20px 0 12px 0;
    padding-bottom: 8px;
    border-bottom: 1px solid #2d3a5f;
}

/* Progress visualization */
.progress-container {
    background-color: #1e2842;
    border: 1px solid #2d3a5f;
    border-radius: 8px;
    padding: 20px;
    margin: 16px 0;
}

.progress-steps {
    display: flex;
    justify-content: space-between;
    align-items: center;
    margin-bottom: 16px;
    position: relative;
}

.progress-step {
    display: flex;
    flex-direction: column;
    align-items: center;
    z-index: 1;
}

.step-circle {
    width: 36px;
    height: 36px;
    border-radius: 50%;
    background-color: #0a0e1a;
    border: 3px solid #2d3a5f;
    display: flex;
    align-items: center;
    justify-content: center;
    font-weight: bold;
    font-size: 14px;
    color: #6b7280;
    transition: all 0.3s ease;
}

.step-circle.active {
    border-color: #4a9eff;
    color: #4a9eff;
    box-shadow: 0 0 12px rgba(74, 158, 255, 0.4);
}

.step-circle.completed {
    background-color: #4a9eff;
    border-color: #4a9eff;
    color: #ffffff;
}

.step-label {
    margin-top: 8px;
    font-size: 10px;
    color: #6b7280;
    text-transform: uppercase;
    letter-spacing: 0.5px;
    text-align: center;
    max-width: 80px;
}

.step-label.active {
    color: #4a9eff;
}

.progress-line {
    position: absolute;
    top: 18px;
    left: 36px;
    right: 36px;
    height: 3px;
    background-color: #2d3a5f;
    z-index: 0;
}

.progress-line-fill {
    height: 100%;
    background: linear-gradient(90deg, #4a9eff, #2d6bbf);
    transition: width 0.5s ease;
}

.progress-bar-container {
    background-color: #0a0e1a;
    border-radius: 4px;
    height: 8px;
    overflow: hidden;
    margin-top: 12px;
}

.progress-bar-fill {
    height: 100%;
    background: linear-gradient(90deg, #4a9eff, #5eaaff);
    transition: width 0.3s ease;
}

.progress-percentage {
    text-align: right;
    font-size: 12px;
    color: #4a9eff;
    margin-top: 4px;
    font-family: 'IBM Plex Mono', monospace;
}

/* Disclaimer/warning */
.disclaimer-box {
    background-color: rgba(255, 149, 0, 0.1);
    border: 1px solid #ff9500;
    border-radius: 8px;
    padding: 12px 16px;
    margin: 16px 0;
    text-align: center;
}

.disclaimer-text {
    color: #ff9500;
    font-size: 12px;
    margin: 0;
}

/* Chart containers */
.chart-container {
    background-color: #0f1320;
    border-radius: 8px;
    padding: 16px;
    margin: 8px 0;
}

/* Monospace output text */
textarea {
    font-family: 'IBM Plex Mono', 'Courier New', monospace !important;
}
"""

COLLAPSIBLE_JS = """
<script>
function toggleCollapsible(element) {
    element.classList.toggle('active');
    var content = element.nextElementSibling;
    content.classList.toggle('show');
}
</script>
"""


def format_analysis_with_collapsibles(text: str, expand_first: bool = True) -> str:
    """
    Parse analysis text and format with collapsible sections.

    Args:
        text: Raw analysis text from AI
        expand_first: Whether to expand the first section by default

    Returns:
        HTML string with collapsible sections
    """
    import re

    if not text or text.startswith("Analysis in progress") or text.startswith("ERROR"):
        return f'<div style="color: #6b7280; padding: 20px;">{text}</div>'

    # Split text into sections by common header patterns
    # Look for ## headers, ** bold headers **, or numbered sections like "1."
    section_pattern = r'(?:^|\n)((?:##\s*.+)|(?:\*\*.+\*\*)|(?:\d+\.\s*[A-Z].+))(?:\n|$)'

    sections = []
    current_section = None
    current_content = []

    lines = text.split('\n')

    for line in lines:
        # Check if this line is a section header
        is_header = False

        # ## Header
        if line.strip().startswith('##'):
            is_header = True
            header_text = line.strip().lstrip('#').strip()
        # **Bold Header**
        elif line.strip().startswith('**') and line.strip().endswith('**'):
            is_header = True
            header_text = line.strip().strip('*').strip()
        # Numbered header like "1. Section Name" or "1) Section Name"
        elif re.match(r'^\d+[\.\)]\s+[A-Z]', line.strip()):
            is_header = True
            header_text = line.strip()

        if is_header:
            # Save previous section
            if current_section is not None:
                sections.append((current_section, '\n'.join(current_content)))
            current_section = header_text
            current_content = []
        else:
            current_content.append(line)

    # Save last section
    if current_section is not None:
        sections.append((current_section, '\n'.join(current_content)))
    elif current_content:
        # No sections found, treat entire text as one section
        sections.append(("Analysis Results", '\n'.join(current_content)))

    # Build HTML
    html_parts = [COLLAPSIBLE_JS]

    for i, (header, content) in enumerate(sections):
        # Determine if section should be expanded
        is_active = "active" if (expand_first and i == 0) else ""
        is_show = "show" if (expand_first and i == 0) else ""

        # Clean up content - escape HTML but preserve structure
        content_escaped = content.strip()
        content_escaped = content_escaped.replace('&', '&amp;')
        content_escaped = content_escaped.replace('<', '&lt;')
        content_escaped = content_escaped.replace('>', '&gt;')

        # Convert markdown-style formatting
        # Bold: **text** -> <strong>text</strong>
        content_escaped = re.sub(r'\*\*(.+?)\*\*', r'<strong style="color: #4a9eff;">\1</strong>', content_escaped)
        # Bullets: - text -> bullet
        content_escaped = re.sub(r'^- (.+)$', r'<span class="analysis-bullet">‚Ä¢</span>\1', content_escaped, flags=re.MULTILINE)
        content_escaped = re.sub(r'^\* (.+)$', r'<span class="analysis-bullet">‚Ä¢</span>\1', content_escaped, flags=re.MULTILINE)

        html_parts.append(f'''
        <div class="collapsible-container">
            <div class="collapsible-header {is_active}" onclick="toggleCollapsible(this)">
                <span class="collapsible-title">{header}</span>
                <span class="collapsible-icon">‚ñº</span>
            </div>
            <div class="collapsible-content {is_show}">{content_escaped}</div>
        </div>
        ''')

    return ''.join(html_parts)


def generate_progress_html(current_step: int, status_message: str = "") -> str:
    """
    Generate HTML for the visual progress indicator.

    Args:
        current_step: Current step number (0-7, where 0 is not started, 7 is complete)
        status_message: Optional status message to display

    Returns:
        HTML string for progress display
    """
    steps = [
        ("1", "Video"),
        ("2", "Audio"),
        ("3", "Visual"),
        ("4", "Multi"),
        ("5", "Voice"),
        ("6", "Synth")
    ]

    # Progress: steps 1-6 are in progress, 7 means complete (100%)
    # Step 6 = synthesis running = 85%, only 7 (complete) = 100%
    if current_step == 0:
        progress_percent = 0
    elif current_step <= 6:
        progress_percent = (current_step / 7) * 100
    else:
        progress_percent = 100

    step_html = ""
    for i, (num, label) in enumerate(steps):
        step_num = i + 1
        if step_num < current_step:
            circle_class = "completed"
            label_class = ""
        elif step_num == current_step:
            circle_class = "active"
            label_class = "active"
        else:
            circle_class = ""
            label_class = ""

        checkmark = "‚úì" if step_num < current_step else num
        step_html += f'''
        <div class="progress-step">
            <div class="step-circle {circle_class}">{checkmark}</div>
            <div class="step-label {label_class}">{label}</div>
        </div>
        '''

    html = f'''
    <div class="progress-container">
        <div class="progress-steps">
            <div class="progress-line">
                <div class="progress-line-fill" style="width: {progress_percent}%"></div>
            </div>
            {step_html}
        </div>
        <div class="progress-bar-container">
            <div class="progress-bar-fill" style="width: {progress_percent}%"></div>
        </div>
        <div class="progress-percentage">{progress_percent:.0f}% Complete</div>
    </div>
    '''
    return html


def save_api_key(api_key):
    """Save API key to encrypted storage."""
    config = ConfigManager()

    if not api_key or not api_key.strip():
        return "‚ö†Ô∏è Please enter an API key", "‚ùå Not Configured"

    # Validate format
    if not api_key.startswith('sk-'):
        return "‚ö†Ô∏è Invalid API key format (should start with 'sk-')", "‚ùå Invalid"

    # Save key
    success = config.save_api_key(api_key.strip())

    if success:
        return "‚úì API key saved successfully (encrypted)", "‚úì Configured"
    else:
        return "‚úó Failed to save API key", "‚ùå Error"


def test_api_key(api_key):
    """Test if API key is valid."""
    config = ConfigManager()

    if not api_key or not api_key.strip():
        # Try to load saved key
        saved_key = config.load_api_key()
        if not saved_key:
            return "‚ö†Ô∏è No API key provided or saved"
        api_key = saved_key

    success, message = config.test_api_key(api_key.strip())
    return message


def load_saved_api_key():
    """Load the saved API key for display."""
    config = ConfigManager()
    key = config.load_api_key()
    if key:
        # Show only first 10 and last 4 characters
        masked = f"{key[:10]}...{key[-4:]}" if len(key) > 14 else key
        return masked, "‚úì Configured"
    return "", "‚ùå Not Configured"


def get_subjects_list():
    """Get list of subjects for dropdown."""
    db = get_database()
    subjects = db.list_subjects()
    if not subjects:
        return []
    return [(f"{s.name} ({s.profile_count} profiles)", s.id) for s in subjects]


def load_subject_profiles(subject_id):
    """Load profiles for a selected subject."""
    if not subject_id:
        return "Select a subject to view their profiles.", [], None

    db = get_database()
    profiles = db.get_profiles_for_subject(subject_id)

    if not profiles:
        return "No profiles found for this subject.", [], None

    # Create summary
    subject = db.get_subject(subject_id)
    summary = f"""## {subject.name}

**Total Profiles:** {len(profiles)}
**First Profiled:** {profiles[-1]['timestamp'][:10] if profiles else 'N/A'}
**Last Profiled:** {profiles[0]['timestamp'][:10] if profiles else 'N/A'}
**Notes:** {subject.notes or 'None'}
"""

    # Create dropdown choices for profile selection
    profile_choices = [
        (f"Report #{p['report_number']} - {p['timestamp'][:10]} ({p['case_id'][:20]})", p['id'])
        for p in profiles
    ]

    return summary, profile_choices, profile_choices[0][1] if profile_choices else None


def load_profile_details(profile_id):
    """Load full details of a specific profile."""
    if not profile_id:
        return ("No profile selected.",) * 6

    db = get_database()
    profile = db.get_profile(profile_id=profile_id)

    if not profile:
        return ("Profile not found.",) * 6

    analyses = profile.get('analyses', {})

    meta = f"""**Case ID:** {profile['case_id']}
**Report #:** {profile['report_number']}
**Date:** {profile['timestamp']}
**Processing Time:** {profile['processing_time']:.2f}s
**Status:** {profile['status']}
**Notes:** {profile.get('notes', 'None')}
"""

    return (
        meta,
        analyses.get('sam_christensen_essence', 'Not available'),
        analyses.get('multimodal_behavioral', 'Not available'),
        analyses.get('audio_voice_analysis', 'Not available'),
        analyses.get('liwc_linguistic_analysis', 'Not available'),
        analyses.get('fbi_behavioral_synthesis', 'Not available')
    )


def refresh_subjects_dropdown():
    """Refresh the subjects dropdown with latest data."""
    choices = get_subjects_list()
    return gr.Dropdown(choices=choices, value=None)


def get_database_stats():
    """Get database statistics for display."""
    db = get_database()
    stats = db.get_stats()

    stats_html = f'''
    <div style="display: grid; grid-template-columns: repeat(3, 1fr); gap: 16px; padding: 16px;">
        <div style="background: #0a0e1a; border: 1px solid #2d3a5f; border-radius: 4px; padding: 16px; text-align: center;">
            <div style="color: #4a9eff; font-size: 28px; font-weight: bold;">{stats['total_subjects']}</div>
            <div style="color: #6b7280; font-size: 12px; text-transform: uppercase;">Subjects</div>
        </div>
        <div style="background: #0a0e1a; border: 1px solid #2d3a5f; border-radius: 4px; padding: 16px; text-align: center;">
            <div style="color: #4a9eff; font-size: 28px; font-weight: bold;">{stats['total_profiles']}</div>
            <div style="color: #6b7280; font-size: 12px; text-transform: uppercase;">Profiles</div>
        </div>
        <div style="background: #0a0e1a; border: 1px solid #2d3a5f; border-radius: 4px; padding: 16px; text-align: center;">
            <div style="color: #4a9eff; font-size: 28px; font-weight: bold;">{stats['average_processing_time']:.1f}s</div>
            <div style="color: #6b7280; font-size: 12px; text-transform: uppercase;">Avg Time</div>
        </div>
    </div>
    '''
    return stats_html


def run_profiling_analysis(video_file, essence_model, multimodal_model, audio_model, liwc_model, synthesis_model, subject_name, subject_notes, use_cache):
    """
    Main function to run profiling analysis on uploaded video.
    Yields progress updates and final results.

    Args:
        video_file: Gradio video file object
        essence_model: Model ID for Sam Christensen analysis
        multimodal_model: Model ID for multimodal analysis
        audio_model: Model ID for audio analysis
        liwc_model: Model ID for LIWC analysis
        synthesis_model: Model ID for FBI synthesis
        subject_name: Name of the subject being profiled
        subject_notes: Optional notes about the subject
        use_cache: Whether to use cached results

    Yields:
        Tuple of (progress_html, status, essence, multimodal, audio, liwc, fbi, transcript, confidence, json_output, json_file)
    """
    # Helper to build yield tuple with optional viz outputs
    def build_yield(progress, status, essence, multimodal, audio, liwc, fbi, transcript, confidence, json_out, file_out, viz_conf=None, viz_big5=None, viz_dark=None, viz_threat=None):
        base = (progress, status, essence, multimodal, audio, liwc, fbi, transcript, confidence, json_out, file_out)
        if VISUALIZATIONS_AVAILABLE:
            return base + (viz_conf, viz_big5, viz_dark, viz_threat)
        return base

    if video_file is None:
        error_msg = "‚ö†Ô∏è ERROR: No video file uploaded"
        yield build_yield(
            generate_progress_html(0), error_msg,
            "No video file provided", "No video file provided", "No video file provided",
            "No video file provided", "No video file provided", "No video file provided",
            "No video file provided", "{}", None
        )
        return

    try:
        # Check if API key is configured
        config = ConfigManager()
        if not config.has_api_key():
            error_msg = "‚ö†Ô∏è ERROR: API key not configured\n\nPlease configure your OpenRouter API key in the Settings section above."
            yield build_yield(
                generate_progress_html(0), error_msg,
                "API key required", "API key required", "API key required",
                "API key required", "API key required", "API key required",
                "API key required", "{}", None
            )
            return

        # Create model selection config
        model_config = ModelSelection(
            essence_model=essence_model,
            multimodal_model=multimodal_model,
            audio_model=audio_model,
            liwc_model=liwc_model,
            synthesis_model=synthesis_model
        )

        # Initialize profiler with selected models
        profiler = BehavioralProfiler(model_config=model_config)

        # Shared state for progress
        current_status = ["‚è≥ Initializing analysis pipeline..."]
        current_step = [0]

        # Progress callback that updates shared state
        def update_progress(message, step):
            current_status[0] = message
            current_step[0] = step

        # Yield initial status
        yield build_yield(
            generate_progress_html(0), current_status[0],
            "Analysis in progress...", "Analysis in progress...", "Analysis in progress...",
            "Analysis in progress...", "Analysis in progress...", "Transcription in progress...",
            "Confidence scoring in progress...", "{}", None
        )

        # Start profiling in a way that allows yielding
        import threading
        import time as time_module

        result_holder = [None]
        error_holder = [None]

        # Shared state for streaming partial results
        partial_results = {
            'essence': "Analysis in progress...",
            'multimodal': "Analysis in progress...",
            'audio': "Analysis in progress...",
            'liwc': "Analysis in progress...",
            'synthesis': "Analysis in progress...",
            'transcript': "Transcription in progress...",
            'confidence': "Confidence scoring in progress..."
        }
        results_lock = threading.Lock()

        # Results callback for streaming
        def update_results(stage, result):
            with results_lock:
                partial_results[stage] = result

        def run_profiling():
            try:
                result_holder[0] = profiler.profile_video(
                    video_path=video_file,
                    progress_callback=update_progress,
                    results_callback=update_results,
                    use_cache=use_cache
                )
            except Exception as e:
                error_holder[0] = e

        # Start analysis thread
        thread = threading.Thread(target=run_profiling)
        thread.start()

        # Yield progress updates while thread is running
        last_status = ""
        last_step = -1
        while thread.is_alive():
            if current_status[0] != last_status or current_step[0] != last_step:
                last_status = current_status[0]
                last_step = current_step[0]

            # Get current partial results
            with results_lock:
                current_essence = partial_results['essence']
                current_multimodal = partial_results['multimodal']
                current_audio = partial_results['audio']
                current_liwc = partial_results['liwc']
                current_synthesis = partial_results['synthesis']
                current_transcript = partial_results['transcript']
                current_confidence = partial_results['confidence']

            yield build_yield(
                generate_progress_html(current_step[0]), current_status[0],
                current_essence, current_multimodal, current_audio,
                current_liwc, current_synthesis, current_transcript,
                current_confidence, "{}", None
            )
            time_module.sleep(0.5)

        thread.join()

        # Check for errors
        if error_holder[0]:
            raise error_holder[0]

        result = result_holder[0]

        # Format results for display
        formatted = profiler.format_result_for_display(result)

        # Create downloadable JSON file
        json_output = json.dumps(result, indent=2, ensure_ascii=False)

        # Create temporary file for download
        temp_file = tempfile.NamedTemporaryFile(
            mode='w',
            suffix='.json',
            delete=False,
            encoding='utf-8'
        )
        temp_file.write(json_output)
        temp_file.close()

        # Save to database if subject name provided
        saved_msg = ""
        if subject_name and subject_name.strip():
            try:
                db = get_database()
                profile_record = db.save_profile(
                    result=result,
                    subject_name=subject_name.strip(),
                    video_source=video_file if isinstance(video_file, str) else "uploaded",
                    notes=subject_notes or ""
                )
                saved_msg = f"\n\nüìÅ Saved as Report #{profile_record.report_number} for '{subject_name.strip()}'"
            except Exception as save_err:
                saved_msg = f"\n\n‚ö†Ô∏è Failed to save to database: {str(save_err)}"

        # Generate visualizations from real data (do this before final status)
        viz_confidence = None
        viz_big_five = None
        viz_dark_triad = None
        viz_threat = None
        viz_status = ""

        if VISUALIZATIONS_AVAILABLE:
            # Yield intermediate status showing visualization generation
            yield build_yield(
                generate_progress_html(6), "‚è≥ Generating visualizations...",
                formatted['essence'], formatted['multimodal'], formatted['audio'],
                formatted['liwc'], formatted['fbi_profile'],
                formatted.get('transcript', 'Transcription not available'),
                formatted.get('confidence', 'Confidence scoring not available'),
                json_output, temp_file.name
            )

            try:
                from visualizations import (
                    create_confidence_gauge,
                    create_big_five_radar,
                    create_dark_triad_bars,
                    create_threat_matrix
                )
                # Create charts from actual analysis data
                confidence_data = result.get('confidence', {})
                analyses = result.get('analyses', {})

                # Use dedicated personality/threat synthesis for scores, fallback to FBI synthesis
                personality_text = analyses.get('personality_synthesis', '') or analyses.get('fbi_behavioral_synthesis', '')
                threat_text = analyses.get('threat_synthesis', '') or analyses.get('fbi_behavioral_synthesis', '')

                viz_confidence = create_confidence_gauge(confidence_data)
                viz_big_five = create_big_five_radar(personality_text)
                viz_dark_triad = create_dark_triad_bars(personality_text)
                viz_threat = create_threat_matrix(threat_text)

                charts_created = sum(1 for v in [viz_confidence, viz_big_five, viz_dark_triad, viz_threat] if v is not None)
                if charts_created > 0:
                    viz_status = f"\nüìä {charts_created} visualization(s) generated"
            except Exception as viz_err:
                logger.warning(f"Visualization generation failed: {viz_err}")
                viz_status = "\n‚ö†Ô∏è Visualizations unavailable"

        # Final status
        final_status = f"""‚úì ANALYSIS COMPLETE

Case ID: {result.get('case_id', 'N/A')}
Processing Time: {result.get('processing_time_seconds', 0):.2f}s
Timestamp: {result.get('timestamp', 'N/A')}

All analyses generated successfully.{viz_status}
Download JSON report below.{saved_msg}"""

        yield build_yield(
            generate_progress_html(7), final_status,  # Step 7 = 100% complete
            formatted['essence'], formatted['multimodal'], formatted['audio'],
            formatted['liwc'], formatted['fbi_profile'],
            formatted.get('transcript', 'Transcription not available'),
            formatted.get('confidence', 'Confidence scoring not available'),
            json_output, temp_file.name,
            viz_confidence, viz_big_five, viz_dark_triad, viz_threat
        )

    except Exception as e:
        error_status = f"""‚ö†Ô∏è ANALYSIS FAILED

Error: {str(e)}

Please check:
1. Video file is valid (.mp4, .mov, .avi, .webm)
2. Video duration is 10-300 seconds (5 minutes max)
3. File size is under 100MB
4. OPENROUTER_API_KEY is set in .env file
5. You have active API credits"""

        yield build_yield(
            generate_progress_html(0), error_status,
            f"ERROR: {str(e)}", f"ERROR: {str(e)}", f"ERROR: {str(e)}",
            f"ERROR: {str(e)}", f"ERROR: {str(e)}", f"ERROR: {str(e)}",
            f"ERROR: {str(e)}", json.dumps({"error": str(e)}, indent=2), None
        )


# Import visualizations module
try:
    from visualizations import (
        create_all_visualizations,
        create_confidence_gauge,
        create_big_five_radar,
        create_dark_triad_bars,
        create_threat_matrix,
        check_plotly_available
    )
    VISUALIZATIONS_AVAILABLE = check_plotly_available()
except ImportError:
    VISUALIZATIONS_AVAILABLE = False


# Create Gradio interface
def create_interface():
    """Create and return the Gradio interface."""

    # Use FBI-themed Glass theme
    fbi_theme = create_fbi_theme()

    with gr.Blocks(css=MINIMAL_CSS, theme=fbi_theme, title="FBI Behavioral Profiler") as app:
        # Clean Header with Attribution
        gr.HTML("""
            <div class="app-header">
                <h1 class="app-title">Behavioral Profiling System</h1>
                <p class="app-subtitle">Multimodal AI-Powered Psychological Assessment</p>
                <p class="app-attribution">Created by <a href="https://x.com/LLMSherpa" target="_blank">@LLMSherpa</a></p>
            </div>
        """)

        # Settings Section
        with gr.Accordion("‚öôÔ∏è Settings & Configuration", open=False):
            gr.Markdown("""
            ### API Key Configuration
            Enter your OpenRouter API key below. The key will be encrypted and saved securely.

            **Get your API key:** [https://openrouter.ai/keys](https://openrouter.ai/keys)
            """)

            with gr.Row():
                with gr.Column(scale=3):
                    api_key_input = gr.Textbox(
                        label="OpenRouter API Key",
                        placeholder="sk-or-v1-...",
                        type="password",
                        info="Your API key is encrypted before being saved"
                    )
                with gr.Column(scale=1):
                    api_status = gr.Textbox(
                        label="Status",
                        value="‚ùå Not Configured",
                        interactive=False,
                        max_lines=1
                    )

            with gr.Row():
                save_key_btn = gr.Button("üíæ Save API Key", variant="primary", size="sm")
                test_key_btn = gr.Button("üîç Test Connection", variant="secondary", size="sm")
                load_key_btn = gr.Button("üìã Load Saved Key", variant="secondary", size="sm")

            api_message = gr.Textbox(
                label="",
                value="",
                interactive=False,
                show_label=False,
                max_lines=2
            )

            gr.Markdown("""
            **Note:** The API key is stored locally in an encrypted format.
            Each analysis costs approximately $0.11-0.23 depending on video complexity.
            """)

            gr.Markdown("---")
            gr.Markdown("""
            ### Model Configuration
            Select which AI models to use for each analysis stage.
            **Note:** Audio/multimodal stages require Gemini models (only Gemini supports audio input).
            """)

            with gr.Row():
                with gr.Column():
                    essence_model_dropdown = gr.Dropdown(
                        choices=ESSENCE_MODEL_CHOICES,
                        value=get_default_model_for_stage("essence"),
                        label="Sam Christensen Analysis (Vision)",
                        info="Model for visual essence profiling"
                    )
                with gr.Column():
                    multimodal_model_dropdown = gr.Dropdown(
                        choices=MULTIMODAL_MODEL_CHOICES,
                        value=get_default_model_for_stage("multimodal"),
                        label="Multimodal Analysis (Vision + Audio)",
                        info="Must be Gemini for audio support"
                    )

            with gr.Row():
                with gr.Column():
                    audio_model_dropdown = gr.Dropdown(
                        choices=AUDIO_MODEL_CHOICES,
                        value=get_default_model_for_stage("audio"),
                        label="Audio/Voice Analysis",
                        info="Must be Gemini for audio support"
                    )
                with gr.Column():
                    liwc_model_dropdown = gr.Dropdown(
                        choices=LIWC_MODEL_CHOICES,
                        value=get_default_model_for_stage("liwc"),
                        label="LIWC Linguistic Analysis",
                        info="Must be Gemini for audio support"
                    )

            with gr.Row():
                with gr.Column():
                    synthesis_model_dropdown = gr.Dropdown(
                        choices=SYNTHESIS_MODEL_CHOICES,
                        value=get_default_model_for_stage("synthesis"),
                        label="FBI Behavioral Synthesis (Text)",
                        info="Model for final profile synthesis"
                    )
                with gr.Column():
                    gr.Markdown("""
                    **Cost Tiers:**
                    - Budget: Faster, cheaper
                    - Standard: Balanced
                    - Premium: Best quality
                    """)

            gr.Markdown("---")
            gr.Markdown("""
            ### Cache Settings
            Cache analysis results to avoid redundant API calls when re-analyzing the same video.
            """)

            with gr.Row():
                use_cache_checkbox = gr.Checkbox(
                    label="Enable Caching",
                    value=True,
                    info="Use cached results when same video+models are analyzed again"
                )
                clear_cache_btn = gr.Button("üóëÔ∏è Clear Cache", size="sm", variant="secondary")
                cache_status = gr.Textbox(
                    label="",
                    value="",
                    interactive=False,
                    show_label=False,
                    max_lines=1,
                    scale=2
                )

            def get_cache_stats_display():
                cache = get_cache()
                stats = cache.get_stats()
                return f"üì¶ {stats['total_entries']} cached | {stats['total_size_mb']:.1f} MB | {stats['total_hits']} hits"

            def clear_all_cache():
                cache = get_cache()
                count = cache.invalidate(all_entries=True)
                return f"‚úì Cleared {count} cache entries"

            clear_cache_btn.click(
                fn=clear_all_cache,
                inputs=[],
                outputs=[cache_status]
            )

        # Prompt Templates Section
        with gr.Accordion("üìù Custom Prompt Templates", open=False):
            gr.Markdown("""
            ### Prompt Template Manager
            Customize the prompts used for each analysis stage. Save your own templates and switch between them.
            """)

            with gr.Row():
                with gr.Column(scale=1):
                    template_stage_select = gr.Dropdown(
                        choices=[(name, stage) for stage, name in PROMPT_STAGES.items()],
                        value="essence",
                        label="Select Analysis Stage",
                        info="Choose which stage to view/edit prompts for"
                    )

                    def get_template_dropdown_choices(stage):
                        tm = get_template_manager()
                        return tm.get_templates_for_dropdown(stage)

                    template_dropdown = gr.Dropdown(
                        choices=get_template_dropdown_choices("essence"),
                        label="Available Templates",
                        info="Select a template to view/edit",
                        interactive=True
                    )

                    with gr.Row():
                        load_template_btn = gr.Button("üìÇ Load", size="sm")
                        set_active_btn = gr.Button("‚úì Set Active", size="sm", variant="primary")

                with gr.Column(scale=2):
                    template_name_input = gr.Textbox(
                        label="Template Name",
                        placeholder="Enter a name for your custom template",
                        max_lines=1
                    )
                    template_desc_input = gr.Textbox(
                        label="Description (optional)",
                        placeholder="Brief description of this template",
                        max_lines=1
                    )

            prompt_editor = gr.Textbox(
                label="Prompt Text",
                placeholder="The prompt text will appear here. Edit and save as a new template.",
                lines=15,
                max_lines=30,
                interactive=True
            )

            template_status = gr.Textbox(
                label="",
                value="Select a stage and template to begin editing.",
                interactive=False,
                show_label=False,
                max_lines=2
            )

            with gr.Row():
                save_template_btn = gr.Button("üíæ Save as New Template", variant="primary")
                update_template_btn = gr.Button("üîÑ Update Template", variant="secondary")
                delete_template_btn = gr.Button("üóëÔ∏è Delete Template", variant="stop")
                reset_default_btn = gr.Button("‚Ü©Ô∏è Reset to Default", variant="secondary")

            # Template management event handlers
            def update_templates_for_stage(stage):
                """Update template dropdown when stage changes."""
                tm = get_template_manager()
                choices = tm.get_templates_for_dropdown(stage)
                # Load the active template's prompt
                active_prompt = tm.get_active_prompt(stage)
                active_id = tm.active_templates.get(stage, "default")
                return (
                    gr.Dropdown(choices=choices, value=active_id if any(c[1] == active_id for c in choices) else choices[0][1] if choices else None),
                    active_prompt,
                    f"Showing active template for {PROMPT_STAGES.get(stage, stage)}"
                )

            template_stage_select.change(
                fn=update_templates_for_stage,
                inputs=[template_stage_select],
                outputs=[template_dropdown, prompt_editor, template_status]
            )

            def load_template_content(template_id, stage):
                """Load a template's content."""
                if not template_id:
                    return "", "", "", "Select a template to load"

                tm = get_template_manager()
                template = tm.get_template(template_id)

                if not template:
                    # It might be "default" - get default prompt
                    if template_id == "default" or template_id.startswith("default_"):
                        return "Default", "", tm.get_default_prompt(stage), "Loaded default template (read-only)"
                    return "", "", "", "Template not found"

                return (
                    template.name if not template.is_default else "Default",
                    template.description,
                    template.prompt_text,
                    f"Loaded: {template.name}" + (" [ACTIVE]" if template.is_active else "")
                )

            load_template_btn.click(
                fn=load_template_content,
                inputs=[template_dropdown, template_stage_select],
                outputs=[template_name_input, template_desc_input, prompt_editor, template_status]
            )

            def set_template_active(template_id, stage):
                """Set a template as active for its stage."""
                if not template_id:
                    return "No template selected"

                tm = get_template_manager()
                success = tm.set_active_template(stage, template_id)

                if success:
                    template = tm.get_template(template_id)
                    name = template.name if template else template_id
                    return f"‚úì Set '{name}' as active for {PROMPT_STAGES.get(stage, stage)}"
                return "Failed to set active template"

            set_active_btn.click(
                fn=set_template_active,
                inputs=[template_dropdown, template_stage_select],
                outputs=[template_status]
            )

            def save_new_template(name, description, prompt_text, stage):
                """Save a new custom template."""
                if not name or not name.strip():
                    return "Error: Template name is required", gr.Dropdown()

                if not prompt_text or not prompt_text.strip():
                    return "Error: Prompt text cannot be empty", gr.Dropdown()

                tm = get_template_manager()
                success, message, template = tm.save_template(
                    name=name.strip(),
                    stage=stage,
                    prompt_text=prompt_text.strip(),
                    description=description
                )

                # Refresh dropdown
                new_choices = tm.get_templates_for_dropdown(stage)

                if success and template:
                    return f"‚úì {message}", gr.Dropdown(choices=new_choices, value=template.id)
                return f"Error: {message}", gr.Dropdown(choices=new_choices)

            save_template_btn.click(
                fn=save_new_template,
                inputs=[template_name_input, template_desc_input, prompt_editor, template_stage_select],
                outputs=[template_status, template_dropdown]
            )

            def update_existing_template(template_id, name, description, prompt_text, stage):
                """Update an existing template."""
                if not template_id:
                    return "No template selected"

                tm = get_template_manager()
                template = tm.get_template(template_id)

                if not template:
                    return "Template not found"

                if template.is_default:
                    return "Cannot modify default templates. Save as a new template instead."

                success, message, _ = tm.save_template(
                    name=name.strip() if name else template.name,
                    stage=stage,
                    prompt_text=prompt_text.strip(),
                    description=description,
                    template_id=template_id
                )

                return f"‚úì {message}" if success else f"Error: {message}"

            update_template_btn.click(
                fn=update_existing_template,
                inputs=[template_dropdown, template_name_input, template_desc_input, prompt_editor, template_stage_select],
                outputs=[template_status]
            )

            def delete_template_handler(template_id, stage):
                """Delete a custom template."""
                if not template_id:
                    return "No template selected", gr.Dropdown()

                tm = get_template_manager()
                success, message = tm.delete_template(template_id)

                new_choices = tm.get_templates_for_dropdown(stage)

                if success:
                    return f"‚úì {message}", gr.Dropdown(choices=new_choices, value=new_choices[0][1] if new_choices else None)
                return f"Error: {message}", gr.Dropdown(choices=new_choices)

            delete_template_btn.click(
                fn=delete_template_handler,
                inputs=[template_dropdown, template_stage_select],
                outputs=[template_status, template_dropdown]
            )

            def reset_to_default_handler(stage):
                """Reset stage to default prompt."""
                tm = get_template_manager()
                tm.reset_to_defaults(stage)

                default_prompt = tm.get_default_prompt(stage)
                new_choices = tm.get_templates_for_dropdown(stage)

                return (
                    f"‚úì Reset {PROMPT_STAGES.get(stage, stage)} to default prompt",
                    default_prompt,
                    gr.Dropdown(choices=new_choices, value=f"default_{stage}")
                )

            reset_default_btn.click(
                fn=reset_to_default_handler,
                inputs=[template_stage_select],
                outputs=[template_status, prompt_editor, template_dropdown]
            )

        # Input Section
        with gr.Row():
            with gr.Column(scale=2):
                gr.HTML('<div class="section-header">Video Input</div>')

                with gr.Tabs():
                    with gr.Tab("Upload File"):
                        video_input = gr.File(
                            label="Subject Video File",
                            file_types=[".mp4", ".mov", ".avi", ".webm"],
                            type="filepath"
                        )

                    with gr.Tab("Import from URL"):
                        url_input = gr.Textbox(
                            label="Video URL",
                            placeholder="https://youtube.com/watch?v=... or direct video URL",
                            info="Supports YouTube, Vimeo, Twitter/X, TikTok, and direct video URLs"
                        )
                        with gr.Row():
                            fetch_url_btn = gr.Button("Fetch Video", variant="secondary", size="sm")
                            url_status = gr.Textbox(
                                label="",
                                value="",
                                interactive=False,
                                show_label=False,
                                max_lines=2
                            )

                gr.Markdown("""
                **Requirements:**
                - Formats: .mp4, .mov, .avi, .webm
                - Duration: 10-300 seconds (5 minutes max)
                - Max size: 100MB
                - Clear view of subject
                """)

                gr.HTML('<div class="section-header" style="margin-top: 15px;">Subject Information</div>')
                with gr.Row():
                    subject_name_input = gr.Textbox(
                        label="Subject Name",
                        placeholder="Enter name to save profile (optional)",
                        info="Name the person/entity to track multiple profiles over time",
                        scale=3
                    )
                    subject_notes_input = gr.Textbox(
                        label="Notes",
                        placeholder="Optional notes...",
                        scale=2
                    )

                analyze_button = gr.Button(
                    "INITIATE BEHAVIORAL ANALYSIS",
                    variant="primary",
                    size="lg"
                )

            with gr.Column(scale=2):
                gr.HTML('<div class="section-header">Video Preview</div>')
                video_preview = gr.Video(
                    label="Preview",
                    show_label=False,
                    height=300
                )
                video_metadata_display = gr.HTML(
                    value='<div style="color: #6b7280; text-align: center; padding: 20px;">Upload a video to see preview and metadata</div>'
                )

        # Connect file upload to video preview
        def update_video_preview(video_file):
            if video_file is None:
                return None, '<div style="color: #6b7280; text-align: center; padding: 20px;">Upload a video to see preview and metadata</div>'

            try:
                from frame_extractor import validate_video_file
                metadata = validate_video_file(video_file)

                duration = metadata.get('duration_seconds', 0)
                mins = int(duration // 60)
                secs = int(duration % 60)

                width, height = metadata.get('resolution', (0, 0))
                fps = metadata.get('fps', 0)
                size_mb = metadata.get('file_size_mb', 0)

                metadata_html = f'''
                <div style="background: #0a0e1a; border: 1px solid #2d3a5f; border-radius: 4px; padding: 12px; margin-top: 10px;">
                    <div style="display: grid; grid-template-columns: 1fr 1fr; gap: 8px; font-family: monospace; font-size: 12px;">
                        <div style="color: #6b7280;">Duration:</div>
                        <div style="color: #4a9eff;">{mins}:{secs:02d}</div>
                        <div style="color: #6b7280;">Resolution:</div>
                        <div style="color: #4a9eff;">{width}x{height}</div>
                        <div style="color: #6b7280;">Frame Rate:</div>
                        <div style="color: #4a9eff;">{fps:.1f} fps</div>
                        <div style="color: #6b7280;">File Size:</div>
                        <div style="color: #4a9eff;">{size_mb:.2f} MB</div>
                    </div>
                    <div style="margin-top: 10px; padding-top: 10px; border-top: 1px solid #2d3a5f;">
                        {"<span style='color: #22c55e;'>‚úì Video meets requirements</span>" if 10 <= duration <= 300 and size_mb <= 100 else "<span style='color: #ef4444;'>‚ö† Video may not meet requirements</span>"}
                    </div>
                </div>
                '''
                return video_file, metadata_html
            except Exception as e:
                return video_file, f'<div style="color: #ef4444; padding: 20px;">Error reading video: {str(e)}</div>'

        video_input.change(
            fn=update_video_preview,
            inputs=[video_input],
            outputs=[video_preview, video_metadata_display]
        )

        # URL fetch handler
        def fetch_video_from_url(url):
            if not url or not url.strip():
                return None, "‚ö†Ô∏è Please enter a URL", None, '<div style="color: #6b7280; text-align: center; padding: 20px;">Upload a video to see preview and metadata</div>'

            url = url.strip()
            if not is_valid_url(url):
                return None, "‚ö†Ô∏è Invalid URL format", None, '<div style="color: #ef4444; padding: 20px;">Invalid URL</div>'

            try:
                # Download the video
                file_path, metadata = download_video(
                    url,
                    max_duration=300,
                    max_filesize_mb=100
                )

                # Create metadata display
                duration = metadata.get('duration_seconds', 0)
                mins = int(duration // 60)
                secs = int(duration % 60)

                metadata_html = f'''
                <div style="background: #0a0e1a; border: 1px solid #2d3a5f; border-radius: 4px; padding: 12px; margin-top: 10px;">
                    <div style="font-weight: bold; color: #4a9eff; margin-bottom: 8px;">{metadata.get('title', 'Unknown')[:50]}</div>
                    <div style="display: grid; grid-template-columns: 1fr 1fr; gap: 8px; font-family: monospace; font-size: 12px;">
                        <div style="color: #6b7280;">Platform:</div>
                        <div style="color: #4a9eff;">{metadata.get('platform', 'Unknown')}</div>
                        <div style="color: #6b7280;">Duration:</div>
                        <div style="color: #4a9eff;">{mins}:{secs:02d}</div>
                        <div style="color: #6b7280;">File Size:</div>
                        <div style="color: #4a9eff;">{metadata.get('file_size_mb', 0):.2f} MB</div>
                        <div style="color: #6b7280;">Uploader:</div>
                        <div style="color: #4a9eff;">{metadata.get('uploader', 'Unknown')[:20]}</div>
                    </div>
                    <div style="margin-top: 10px; padding-top: 10px; border-top: 1px solid #2d3a5f;">
                        <span style='color: #22c55e;'>‚úì Video downloaded successfully</span>
                    </div>
                </div>
                '''

                return file_path, f"‚úì Downloaded: {metadata.get('title', 'Video')[:30]}", file_path, metadata_html

            except ImportError as e:
                return None, "‚ö†Ô∏è yt-dlp not installed. Run: pip install yt-dlp", None, '<div style="color: #ef4444; padding: 20px;">yt-dlp required</div>'
            except ValueError as e:
                return None, f"‚ö†Ô∏è {str(e)}", None, f'<div style="color: #ef4444; padding: 20px;">{str(e)}</div>'
            except Exception as e:
                return None, f"‚ö†Ô∏è Download failed: {str(e)}", None, f'<div style="color: #ef4444; padding: 20px;">Error: {str(e)}</div>'

        fetch_url_btn.click(
            fn=fetch_video_from_url,
            inputs=[url_input],
            outputs=[video_input, url_status, video_preview, video_metadata_display]
        )

        # Processing Status
        gr.HTML('<div class="section-header">Processing Status</div>')
        progress_html = gr.HTML(
            value=generate_progress_html(0),
            visible=True
        )
        status_display = gr.Textbox(
            label="",
            value="‚è≥ Ready to begin analysis. Upload video and click the button above.",
            lines=4,
            max_lines=6,
            interactive=False,
            show_label=False
        )

        # Results Section - Consolidated into 2 tabs with collapsible sections
        gr.HTML('<div class="section-header" style="margin-top: 30px;">Analysis Results</div>')

        with gr.Tabs():
            with gr.Tab("üìä Analysis Components"):
                gr.Markdown("*Individual analysis stages - click to expand each section*")

                with gr.Accordion("üé≠ Behavioral Archetype (Visual Essence)", open=False):
                    essence_output = gr.Textbox(
                        label="Forensic Visual Essence Analysis",
                        value="Results will appear here after analysis...",
                        lines=20,
                        interactive=False,
                        show_copy_button=True
                    )

                with gr.Accordion("üî¨ Multimodal Behavioral Analysis", open=False):
                    multimodal_output = gr.Textbox(
                        label="Comprehensive Multimodal Analysis (Video + Audio)",
                        value="Results will appear here after analysis...",
                        lines=20,
                        interactive=False,
                        show_copy_button=True
                    )

                with gr.Accordion("üé§ Audio/Voice Analysis", open=False):
                    audio_output = gr.Textbox(
                        label="Voice Forensics & Paralinguistic Analysis",
                        value="Results will appear here after analysis...",
                        lines=20,
                        interactive=False,
                        show_copy_button=True
                    )

                with gr.Accordion("üìù LIWC Linguistic Analysis", open=False):
                    liwc_output = gr.Textbox(
                        label="Linguistic Inquiry & Word Count Analysis",
                        value="Results will appear here after analysis...",
                        lines=20,
                        interactive=False,
                        show_copy_button=True
                    )

                with gr.Accordion("üó£Ô∏è Speech Transcript", open=False):
                    transcript_output = gr.Textbox(
                        label="Audio Transcription",
                        value="Speech transcript will appear here after analysis...",
                        lines=15,
                        interactive=False,
                        show_copy_button=True
                    )

            with gr.Tab("üéØ FBI Profile & Insights"):
                gr.Markdown("*Synthesized behavioral profile with visual analytics*")

                # Visual Analytics Row (charts)
                if VISUALIZATIONS_AVAILABLE:
                    with gr.Row():
                        with gr.Column(scale=1):
                            confidence_gauge = gr.Plot(
                                label="Confidence",
                                show_label=False
                            )
                        with gr.Column(scale=2):
                            big_five_chart = gr.Plot(
                                label="Personality Profile",
                                show_label=False
                            )

                    with gr.Row():
                        with gr.Column(scale=1):
                            dark_triad_chart = gr.Plot(
                                label="Dark Triad",
                                show_label=False
                            )
                        with gr.Column(scale=1):
                            threat_chart = gr.Plot(
                                label="Threat Assessment",
                                show_label=False
                            )
                else:
                    # Placeholder variables if visualizations not available
                    confidence_gauge = gr.State(None)
                    big_five_chart = gr.State(None)
                    dark_triad_chart = gr.State(None)
                    threat_chart = gr.State(None)

                with gr.Accordion("üìã FBI Behavioral Synthesis", open=True):
                    fbi_output = gr.Textbox(
                        label="FBI-Style Psychological Assessment & Recommendations",
                        value="Results will appear here after analysis...",
                        lines=30,
                        interactive=False,
                        show_copy_button=True
                    )

                with gr.Accordion("üìä Confidence Details", open=False):
                    confidence_output = gr.Textbox(
                        label="Analysis Confidence Assessment",
                        value="Confidence assessment will appear here after analysis...",
                        lines=15,
                        interactive=False,
                        show_copy_button=True
                    )

                with gr.Accordion("üîß Complete JSON Data", open=False):
                    json_output = gr.Textbox(
                        label="Full Analysis Report (JSON Format)",
                        value="{}",
                        lines=20,
                        interactive=False,
                        show_copy_button=True
                    )

        # Download Section
        gr.HTML('<div class="section-header">Export Report</div>')
        with gr.Row():
            download_button = gr.File(
                label="Download JSON Report",
                type="filepath"
            )
            pdf_download = gr.File(
                label="Download PDF Report",
                type="filepath"
            )

        with gr.Row():
            generate_pdf_btn = gr.Button(
                "üìÑ Generate PDF Report",
                variant="secondary",
                size="sm",
                interactive=REPORTLAB_AVAILABLE
            )
            pdf_status = gr.Textbox(
                label="",
                value="" if REPORTLAB_AVAILABLE else "‚ö†Ô∏è reportlab not installed",
                interactive=False,
                show_label=False,
                max_lines=1,
                scale=2
            )

        # Profile History Section
        with gr.Accordion("üìÅ Profile History", open=False):
            gr.Markdown("""
            ### Saved Profiles
            Browse previously analyzed subjects and their profile history.
            """)

            # Stats display
            history_stats = gr.HTML(value=get_database_stats())
            refresh_stats_btn = gr.Button("üîÑ Refresh Stats", size="sm")
            refresh_stats_btn.click(
                fn=get_database_stats,
                inputs=[],
                outputs=[history_stats]
            )

            gr.Markdown("---")

            with gr.Row():
                with gr.Column(scale=1):
                    gr.Markdown("**Select Subject**")
                    subject_dropdown = gr.Dropdown(
                        choices=get_subjects_list(),
                        label="Subject",
                        info="Select a subject to view their profiles",
                        interactive=True
                    )
                    refresh_subjects_btn = gr.Button("üîÑ Refresh List", size="sm")

                with gr.Column(scale=2):
                    subject_summary = gr.Markdown(
                        value="Select a subject to view their profile history."
                    )

            with gr.Row():
                profile_dropdown = gr.Dropdown(
                    choices=[],
                    label="Select Profile Report",
                    info="Choose a specific analysis to view",
                    interactive=True
                )

            # Profile details display
            with gr.Accordion("Profile Details", open=True):
                history_meta = gr.Markdown(value="*Select a profile to view details*")

                with gr.Tabs():
                    with gr.Tab("Essence"):
                        history_essence = gr.Textbox(
                            label="Sam Christensen Essence",
                            value="",
                            lines=15,
                            interactive=False,
                            show_copy_button=True
                        )
                    with gr.Tab("Multimodal"):
                        history_multimodal = gr.Textbox(
                            label="Multimodal Analysis",
                            value="",
                            lines=15,
                            interactive=False,
                            show_copy_button=True
                        )
                    with gr.Tab("Audio"):
                        history_audio = gr.Textbox(
                            label="Audio/Voice Analysis",
                            value="",
                            lines=15,
                            interactive=False,
                            show_copy_button=True
                        )
                    with gr.Tab("LIWC"):
                        history_liwc = gr.Textbox(
                            label="LIWC Analysis",
                            value="",
                            lines=15,
                            interactive=False,
                            show_copy_button=True
                        )
                    with gr.Tab("FBI Profile"):
                        history_fbi = gr.Textbox(
                            label="FBI Behavioral Synthesis",
                            value="",
                            lines=15,
                            interactive=False,
                            show_copy_button=True
                        )

            # Event handlers for history browsing
            def update_subject_selection(subject_id):
                summary, choices, default = load_subject_profiles(subject_id)
                return summary, gr.Dropdown(choices=choices, value=default)

            subject_dropdown.change(
                fn=update_subject_selection,
                inputs=[subject_dropdown],
                outputs=[subject_summary, profile_dropdown]
            )

            profile_dropdown.change(
                fn=load_profile_details,
                inputs=[profile_dropdown],
                outputs=[
                    history_meta,
                    history_essence,
                    history_multimodal,
                    history_audio,
                    history_liwc,
                    history_fbi
                ]
            )

            def do_refresh_subjects():
                choices = get_subjects_list()
                return gr.Dropdown(choices=choices, value=None)

            refresh_subjects_btn.click(
                fn=do_refresh_subjects,
                inputs=[],
                outputs=[subject_dropdown]
            )

        # ==================================================================================
        # DEVELOPER META-ANALYSIS SECTION - TO REMOVE BEFORE PRODUCTION
        # ==================================================================================
        with gr.Accordion("üõ†Ô∏è [DEV] Meta-Analysis (REMOVE BEFORE UPLOAD)", open=False):
            gr.Markdown("""
            ### Developer Meta-Analysis
            **‚ö†Ô∏è This section is for DEVELOPMENT ONLY and should be REMOVED before production upload.**

            This sends the complete profiling report to Gemini 3 Pro for analysis of:
            - Profiler system improvements
            - Workflow optimization suggestions
            - Behavioral analysis quality feedback
            - Prompt engineering recommendations
            """)

            with gr.Row():
                dev_meta_model = gr.Dropdown(
                    choices=[(f"{m.name} ({m.provider})", m.id) for m in DEV_META_MODELS],
                    value=DEFAULT_DEV_META_MODEL,
                    label="Meta-Analysis Model",
                    info="Model to use for meta-analysis"
                )
                run_meta_btn = gr.Button(
                    "üîç Run Meta-Analysis",
                    variant="secondary",
                    size="sm"
                )

            dev_meta_status = gr.Textbox(
                label="",
                value="Click 'Run Meta-Analysis' after completing an analysis to get feedback.",
                interactive=False,
                show_label=False,
                max_lines=2
            )

            dev_meta_output = gr.Textbox(
                label="Meta-Analysis Feedback",
                value="",
                lines=30,
                interactive=False,
                show_copy_button=True
            )

            # Meta-analysis handler
            def run_meta_analysis_handler(json_str, model_id):
                """Run developer meta-analysis on the current result."""
                if not json_str or json_str == "{}" or json_str.startswith('{"error"'):
                    return "‚ö†Ô∏è No analysis results available. Run analysis first.", ""

                try:
                    import json as json_module
                    result = json_module.loads(json_str)

                    # Run meta-analysis
                    meta_feedback = run_dev_meta_analysis(
                        result=result,
                        model=model_id
                    )

                    return "‚úì Meta-analysis complete", meta_feedback

                except Exception as e:
                    return f"‚ö†Ô∏è Meta-analysis failed: {str(e)}", ""

            run_meta_btn.click(
                fn=run_meta_analysis_handler,
                inputs=[json_output, dev_meta_model],
                outputs=[dev_meta_status, dev_meta_output]
            )

        # Footer
        gr.HTML("""
            <div class="disclaimer-box">
                <p class="disclaimer-text">
                    ‚ö†Ô∏è Research & Educational Use Only ‚Ä¢ Subject Consent Required ‚Ä¢ No Unauthorized Surveillance
                </p>
            </div>
        """)

        gr.Markdown("""
        ---
        **Processing Pipeline:** Keyframe Extraction ‚Üí Audio Analysis ‚Üí Visual Essence ‚Üí Multimodal Behavioral ‚Üí Linguistic Analysis ‚Üí FBI Synthesis

        *Powered by OpenRouter API ‚Ä¢ ~1-2 min processing time*
        """)

        # Event handlers for Settings
        save_key_btn.click(
            fn=save_api_key,
            inputs=[api_key_input],
            outputs=[api_message, api_status]
        )

        test_key_btn.click(
            fn=test_api_key,
            inputs=[api_key_input],
            outputs=[api_message]
        )

        load_key_btn.click(
            fn=load_saved_api_key,
            inputs=[],
            outputs=[api_key_input, api_status]
        )

        # Event handler for Analysis - build outputs list
        analysis_outputs = [
            progress_html,
            status_display,
            essence_output,
            multimodal_output,
            audio_output,
            liwc_output,
            fbi_output,
            transcript_output,
            confidence_output,
            json_output,
            download_button
        ]

        # Add visualization outputs if available
        if VISUALIZATIONS_AVAILABLE:
            analysis_outputs.extend([
                confidence_gauge,
                big_five_chart,
                dark_triad_chart,
                threat_chart
            ])

        analyze_button.click(
            fn=run_profiling_analysis,
            inputs=[
                video_input,
                essence_model_dropdown,
                multimodal_model_dropdown,
                audio_model_dropdown,
                liwc_model_dropdown,
                synthesis_model_dropdown,
                subject_name_input,
                subject_notes_input,
                use_cache_checkbox
            ],
            outputs=analysis_outputs
        )

        # PDF generation handler
        def generate_pdf_from_results(json_str, subject_name):
            """Generate PDF from the JSON results."""
            if not REPORTLAB_AVAILABLE:
                return None, "‚ö†Ô∏è reportlab not installed. Run: pip install reportlab"

            if not json_str or json_str == "{}" or json_str.startswith('{"error"'):
                return None, "‚ö†Ô∏è No analysis results to export. Run analysis first."

            try:
                import json as json_module
                result = json_module.loads(json_str)

                pdf_path = generate_pdf_report(
                    result=result,
                    subject_name=subject_name if subject_name else None
                )

                return pdf_path, "‚úì PDF generated successfully"
            except Exception as e:
                return None, f"‚ö†Ô∏è PDF generation failed: {str(e)}"

        generate_pdf_btn.click(
            fn=generate_pdf_from_results,
            inputs=[json_output, subject_name_input],
            outputs=[pdf_download, pdf_status]
        )

        # Load API key status on startup
        app.load(
            fn=lambda: load_saved_api_key()[1],
            inputs=[],
            outputs=[api_status]
        )

    return app


if __name__ == "__main__":
    # Check for API key
    config = ConfigManager()
    if not config.has_api_key():
        print("\n" + "="*70)
        print("‚ö†Ô∏è  API KEY NOT CONFIGURED")
        print("="*70)
        print("\nConfigure your OpenRouter API key via the web interface:")
        print("1. Launch the app (it will open in your browser)")
        print("2. Click '‚öôÔ∏è Settings & Configuration'")
        print("3. Enter your API key and click 'Save'")
        print("4. Get your key from: https://openrouter.ai/keys")
        print("\nAlternatively, edit .env file manually.")
        print("\n" + "="*70 + "\n")

    # Create and launch interface
    app = create_interface()

    print("\n" + "="*70)
    print("FBI-STYLE BEHAVIORAL PROFILING SYSTEM")
    print("="*70)
    print("\nüöÄ Launching Gradio interface...")
    print("üìä System ready for multimodal analysis")
    if config.has_api_key():
        print("‚úÖ API key configured")
    else:
        print("‚ö†Ô∏è  Configure API key in Settings panel")
    print("\n" + "="*70 + "\n")

    # Find an available port starting from 7861
    import socket

    def find_available_port(start_port=7861, max_attempts=10):
        for port in range(start_port, start_port + max_attempts):
            try:
                with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:
                    s.bind(('localhost', port))
                    return port
            except OSError:
                continue
        return start_port  # Fallback

    port = find_available_port()
    print(f"üåê Starting on port {port}")

    app.launch(
        server_name="localhost",
        server_port=port,
        share=False,
        show_error=True
    )
